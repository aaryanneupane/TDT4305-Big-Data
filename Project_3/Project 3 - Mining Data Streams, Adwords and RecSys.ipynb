{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c461633a",
   "metadata": {},
   "source": [
    "## Enter full names of group members:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4648c5",
   "metadata": {},
   "source": [
    "##### Name A: Aaryan Neupane\n",
    "##### Name B: Anne Torgersen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30d55dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sympy import prime\n",
    "from pathlib import Path  # for paths of files\n",
    "import csv\n",
    "import copy\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ANSI escape codes for colors\n",
    "class colors:\n",
    "    red = '\\033[91m'\n",
    "    green = '\\033[92m'\n",
    "    blue = '\\033[94m'\n",
    "    end = '\\033[0m'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d4a780",
   "metadata": {},
   "source": [
    "### 1. DGIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9287695e",
   "metadata": {},
   "source": [
    "#### 1.1. DGIM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af55744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default DGIM parameters\n",
    "\n",
    "stream_path = 'data/my_stream.txt'\n",
    "\n",
    "# The window size\n",
    "N = 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2573a3fb-16b5-4d40-83d9-58074c22a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def shift_buckets(bucket_list):\n",
    "    for i in range(len(bucket_list) - 1):\n",
    "        if len(bucket_list[i]) > 2:\n",
    "            prev_time = bucket_list[i].pop(0)\n",
    "            penultimate_time = bucket_list[i].pop(0)\n",
    "            bucket_list[i+1].append(penultimate_time)\n",
    "\n",
    "def remove_expired(bucket_list, end_time, N):\n",
    "    for bucket in bucket_list:\n",
    "        for time_stamp in bucket:\n",
    "            if (end_time - time_stamp) > N:\n",
    "                bucket.remove(time_stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f339cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgim_algorithm(stream_path, N):\n",
    "    num_buckets = int(N).bit_length()\n",
    "    bucket_list = [[] for _ in range(num_buckets)]\n",
    "    time = 0\n",
    "    with open(stream_path) as file:\n",
    "        while True:\n",
    "            bit = file.read(1)\n",
    "\n",
    "            if not bit:\n",
    "                break\n",
    "                \n",
    "            time += 1\n",
    "\n",
    "            if bit == '1':\n",
    "                bucket_list[0].append(time)\n",
    "                shift_buckets(bucket_list)\n",
    "                remove_expired(bucket_list, time, N)\n",
    "\n",
    "    bucket_list = [[elem % N for elem in bucket] for bucket in bucket_list]\n",
    "            \n",
    "    end_time = max(bucket_list[0])\n",
    "    \n",
    "    return bucket_list, end_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc1d2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated list of timestamps buckets from DGIM algorithm: \n",
      " [[99], [91, 96], [83, 89], [63, 75], [44], [6], [321, 446], [188], []]\n",
      "The end timestamp: 99\n"
     ]
    }
   ],
   "source": [
    "bucket = dgim_algorithm(stream_path, N)\n",
    "print(f\"The updated list of timestamps buckets from DGIM algorithm: \\n {bucket[0]}\")\n",
    "print(f\"The end timestamp: {bucket[1]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c273257",
   "metadata": {},
   "source": [
    "#### 1.2. Query the Bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb0343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_count(stream_path, k):\n",
    "    stream_list = []\n",
    "    with open(stream_path, 'r') as file:\n",
    "        for line in file:\n",
    "            stream_list.extend(list(map(int, line.strip())))\n",
    "\n",
    "    # Convert the list into a numpy array\n",
    "    stream_array = np.array(stream_list)\n",
    "    \n",
    "    return int(np.sum(stream_array[-k:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f7f130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgim_query(bucket_list, N, k):  \n",
    "    bucket_list, end_time_stamp = bucket_list\n",
    "    \n",
    "    boxes_to_check = 1\n",
    "    prev_time = 0\n",
    "    for bucket in bucket_list:\n",
    "        if len(bucket) == 0:\n",
    "            break\n",
    "        if max(bucket) == end_time_stamp:\n",
    "            continue\n",
    "            \n",
    "        time = abs(end_time_stamp - min(bucket))\n",
    "        if time >= k:\n",
    "            break\n",
    " \n",
    "        prev_time = abs(end_time_stamp - min(bucket)) + prev_time\n",
    "        \n",
    "        if prev_time >= k:\n",
    "            boxes_to_check += 1\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            boxes_to_check += 1\n",
    "            continue\n",
    "            \n",
    "    one_count = 0\n",
    "    for i in range(boxes_to_check):    \n",
    "        if i == boxes_to_check:\n",
    "            if len(bucket_list[i]) == 2:\n",
    "                one_count += (1 * 2**i) + (1 * 2**i)//2\n",
    "            elif len(bucket_list[i]) == 1:\n",
    "                one_count += (1 * 2**i) //2\n",
    "        one_count += len(bucket_list[i]) * 2**i\n",
    "\n",
    "    return math.ceil(one_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "387e5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of queries\n",
    "K = [10, 50, 100, 200, 300, 400, 500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7702bc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "The total 1s in the last 10 bits by DGIM: 5\n",
      "The true count of 1s in the last 10 bits: 5\n",
      "The DGIM error for predicted 1s in the last 10 bits:     0.0 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 50 bits by DGIM: 29\n",
      "The true count of 1s in the last 50 bits: 26\n",
      "The DGIM error for predicted 1s in the last 50 bits:     11.54 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 100 bits by DGIM: 45\n",
      "The true count of 1s in the last 100 bits: 51\n",
      "The DGIM error for predicted 1s in the last 100 bits:     11.76 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 200 bits by DGIM: 77\n",
      "The true count of 1s in the last 200 bits: 105\n",
      "The DGIM error for predicted 1s in the last 200 bits:     26.67 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 300 bits by DGIM: 205\n",
      "The true count of 1s in the last 300 bits: 150\n",
      "The DGIM error for predicted 1s in the last 300 bits:     36.67 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 400 bits by DGIM: 205\n",
      "The true count of 1s in the last 400 bits: 199\n",
      "The DGIM error for predicted 1s in the last 400 bits:     3.02 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 500 bits by DGIM: 333\n",
      "The true count of 1s in the last 500 bits: 241\n",
      "The DGIM error for predicted 1s in the last 500 bits:     38.17 %\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------------\")\n",
    "for k in K:\n",
    "    dgim_count = dgim_query(bucket, 500, k)\n",
    "    true_count = actual_count(stream_path, k)\n",
    "    \n",
    "    print(f\"The total 1s in the last {k} bits by DGIM: {dgim_count}\")\n",
    "    print(f\"The true count of 1s in the last {k} bits: {true_count}\")\n",
    "    print(f\"The DGIM error for predicted 1s in the last {k} bits: \\\n",
    "    {round(abs(100*(dgim_count-true_count))/true_count,2)} %\")\n",
    "    print(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaaceac",
   "metadata": {},
   "source": [
    "### 2. Bloom filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92883c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Username data for the creation of bloom filters - B\n",
    "data_file = (Path(\"data/bloom_username\").with_suffix('.csv'))\n",
    "\n",
    "# Test data to check the functionality and false positive rate\n",
    "test1_file = (Path(\"data/test1_username\").with_suffix('.csv'))\n",
    "test2_file = (Path(\"data/test2_username\").with_suffix('.csv'))\n",
    "\n",
    "# Default bloom filter parameters\n",
    "bloom_size = 1500000 # parameter N\n",
    "h = 3 # number of hash functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c5e5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of bloom filter with zeros\n",
    "B = np.zeros(bloom_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c033746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d73d660",
   "metadata": {},
   "source": [
    "#### 2.1. Create Bloom filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75b69edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hash(h, N):\n",
    "\n",
    "    hash_list = []\n",
    "    primes = [n for n in range(2, N) if all(n % x != 0 for x in range(2, int(math.sqrt(n)) + 1))]\n",
    "\n",
    "    for _ in range(h):\n",
    "        p = random.choice(primes)\n",
    "        \n",
    "        def hash_function(s, p, N):\n",
    "            hash_value = sum(ord(char) * p**i for i, char in enumerate(s)) % N\n",
    "            return hash_value\n",
    "\n",
    "        # Create a lambda function that uses the current p and N\n",
    "        hf = lambda s: hash_function(s, p, N)\n",
    "        \n",
    "        hash_list.append(hf)  # Store the lambda function\n",
    "                    \n",
    "    return hash_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a75aeecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = generate_hash(h, bloom_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d2d4c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bloom_filter(B, hashes, data):\n",
    "    with data.open() as f:\n",
    "        for name in f:\n",
    "            p = random.choice([n for n in range(2, N) if all(n % x != 0 for x in range(2, int(math.sqrt(n)) + 1))])\n",
    "            for h in hashes:\n",
    "                hashed_value = sum(ord(char) * p**i for i, char in enumerate(name.strip())) % N\n",
    "                B[hashed_value] = 1\n",
    "            \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe79b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom_array = create_bloom_filter(B, hashes, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7ce957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(bloom_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff48616",
   "metadata": {},
   "source": [
    "#### 2.2. Verify usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "530485d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_verify_username(bloom_array, hashes, new_user):\n",
    "    for h in hashes:\n",
    "        hashed_value = h(new_user)\n",
    "        if B[hashed_value] == 0:\n",
    "            code = 0  # Username is definitely available\n",
    "        else: code = 1  # Username is likely taken\n",
    "    \n",
    "    # To-do! verify username and return a code of 0 or 1 (1 - username taken and 0 - username available)\n",
    "        \n",
    "    return code\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6edf315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to test different usernames here\n",
    "\n",
    "new_username = \"KazeemTDT4305\"\n",
    "\n",
    "# new_username = \"ShambaTDT4305\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22690d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_code = single_verify_username(bloom_array, hashes, new_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7730361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mUsername KazeemTDT4305 is available. Congrats!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if user_code == 1:\n",
    "    print(colors.red + f\"Username {new_username} has been taken. Try again!\" + colors.end)\n",
    "elif user_code == 0:\n",
    "    print(colors.green + f\"Username {new_username} is available. Congrats!\" + colors.end)\n",
    "else:\n",
    "    print(colors.blue + f\"Wrong pass code. Please reverify!\" + colors.end)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "080d7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_verify_username(bloom_array, hashes, data):\n",
    "    # Initialize counts\n",
    "    total_name = 0\n",
    "    taken_name = 0\n",
    "    \n",
    "    with data.open() as f:\n",
    "        for name in f:\n",
    "            total_name += 1\n",
    "            name = name.strip()  # Remove whitespace\n",
    "            \n",
    "            # Check if the username is taken\n",
    "            if single_verify_username(bloom_array, hashes, name) == 1:\n",
    "                taken_name += 1\n",
    "                \n",
    "    # Calculate and return the percentage of taken usernames\n",
    "    if total_name == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return round(taken_name / total_name * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4725c4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "Percentage of username seen before from test 1: 0.03%\n",
      "----------------------------------------------------------\n",
      "Percentage of username seen before from test 2: 0.03%\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------\")\n",
    "user_total = group_verify_username(bloom_array, hashes, test1_file)\n",
    "print(f\"Percentage of username seen before from test 1: {user_total}%\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "user_total = group_verify_username(bloom_array, hashes, test2_file)\n",
    "print(f\"Percentage of username seen before from test 2: {user_total}%\")\n",
    "print(\"----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488c00b",
   "metadata": {},
   "source": [
    "### 3. Flajolet-Martin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dae74f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flajolet_martin(input_stream):\n",
    "    R = 0  # Initialize maximum rightmost zero bit position to 0\n",
    "    counter = 0 \n",
    "    \n",
    "    def h(x):\n",
    "        hash_output = (6 * x + 1) % 5\n",
    "        return hash_output\n",
    "        \n",
    "    while counter != (len(input_stream)-1):\n",
    "        \n",
    "        val = bin(h(input_stream[counter]))[2:]\n",
    "        count = 0 \n",
    "        \n",
    "        for bit in reversed(val):\n",
    "            if bit == '0':\n",
    "                count += 1\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        if count > R:\n",
    "            R = count\n",
    "        counter += 1\n",
    "        \n",
    "    distinct_estimate = 2**R\n",
    "\n",
    "    return distinct_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7a283b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Distinct elements (estimated) in input stream 1: 2\n",
      "-----------------------------------------------------\n",
      "Distinct elements (estimated) in input stream 2: 4\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Input stream\n",
    "input_stream1 = [1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1]\n",
    "input_stream2 = [1, 3, 2, 1, 2, 3, 4, 3, 1, 2, 3, 1]\n",
    "\n",
    "# Run the Flajolet-Martin algorithm\n",
    "distinct_estimate1 = flajolet_martin(input_stream1)\n",
    "distinct_estimate2 = flajolet_martin(input_stream2)\n",
    "\n",
    "# Print the estimated number of distinct elements\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(f\"Distinct elements (estimated) in input stream 1:\", distinct_estimate1)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(f\"Distinct elements (estimated) in input stream 2:\", distinct_estimate2)\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3051ee5",
   "metadata": {},
   "source": [
    "### 4. Adword "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b08ba",
   "metadata": {},
   "source": [
    "#### 4.1. Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a58d6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User queries\n",
    "queries = [\"big data\", \"big data\", \"big data\",\"bloom filters\", \"bloom filters\", \"bloom filters\",\n",
    "           \"flajolet martin\", \"flajolet martin\", \"flajolet martin\", \"dgim algorithm\", \"dgim algorithm\", \"dgim algorithm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66ee11dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Company A B C and D keywords and budget $$$\n",
    "global_companies = {\n",
    "        'A': [\"big data\", \"bloom filters\", 3],\n",
    "        'B': [\"flajolet martin\", 3],\n",
    "        'C': [\"flajolet martin\", \"dgim algorithm\", 3],\n",
    "        'D': [\"big data\", 3],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd6eb986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_algorithm(local_companies, queries):\n",
    "    # Initial revenue\n",
    "    revenue = 0     \n",
    "    for query in queries:\n",
    "        # Collect companies that have bid for the query and have a positive budget\n",
    "        available_companies = [company for company, company_data in local_companies.items() if query in company_data[:-1] and company_data[-1] > 0]\n",
    "        \n",
    "        if available_companies:\n",
    "            # Randomly select one company\n",
    "            selected_company = random.choice(available_companies)\n",
    "            \n",
    "            # Increment revenue and decrement the selected company's budget\n",
    "            revenue += 1\n",
    "            local_companies[selected_company][-1] -= 1  # Decrement the budget of the selected company\n",
    "            \n",
    "    return revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c9378f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trials using Greedy Algorithm...\n",
      "------------------------------------------------\n",
      "Trial 1 - Revenue generated: 10\n",
      "Trial 2 - Revenue generated: 8\n",
      "Trial 3 - Revenue generated: 9\n",
      "Trial 4 - Revenue generated: 9\n",
      "Trial 5 - Revenue generated: 7\n",
      "Trial 6 - Revenue generated: 9\n",
      "Trial 7 - Revenue generated: 10\n",
      "Trial 8 - Revenue generated: 10\n",
      "Trial 9 - Revenue generated: 11\n",
      "Trial 10 - Revenue generated: 10\n",
      "------------------------------------------------\n",
      "Average revenue generated for all trials:  9.3\n"
     ]
    }
   ],
   "source": [
    "total_revenue = 0\n",
    "total_trials = 10\n",
    "print(\"Starting trials using Greedy Algorithm...\")\n",
    "print(\"------------------------------------------------\")\n",
    "for i in range(total_trials):\n",
    "    local_companies = copy.deepcopy(global_companies)\n",
    "    revenue = greedy_algorithm(local_companies, queries)\n",
    "    total_revenue = total_revenue + revenue\n",
    "    print(f\"Trial {i+1} - Revenue generated: {revenue}\")\n",
    "print(\"------------------------------------------------\")   \n",
    "print(\"Average revenue generated for all trials: \",total_revenue/total_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49fda97",
   "metadata": {},
   "source": [
    "#### 4.2. Balance Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9af1b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_algorithm(local_companies, queries):\n",
    "    # Initial revenue\n",
    "    revenue = 0\n",
    "    \n",
    "    for query in queries:\n",
    "        # Collect companies that have bid for the query and have a positive budget\n",
    "        available_companies = [company for company, company_data in local_companies.items() if query in company_data[:-1] and company_data[-1] > 0]\n",
    "        \n",
    "        if available_companies:\n",
    "            # Select the advertiser with the largest remaining budget for the query\n",
    "            max_budget = max([local_companies[company][-1] for company in available_companies])\n",
    "            tied_companies = [company for company in available_companies if local_companies[company][-1] == max_budget]\n",
    "            \n",
    "            # Randomly select one company from the tied companies\n",
    "            selected_company = random.choice(tied_companies)\n",
    "            \n",
    "            # Increment revenue and decrement the selected company's budget\n",
    "            revenue += 1\n",
    "            local_companies[selected_company][-1] -= 1  # Decrement the budget of the selected company\n",
    "    \n",
    "    return revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b975413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trials using Balance Algorithm...\n",
      "-------------------------------------------\n",
      "Trial 1 - Revenue generated: 8\n",
      "Trial 2 - Revenue generated: 9\n",
      "Trial 3 - Revenue generated: 10\n",
      "Trial 4 - Revenue generated: 9\n",
      "Trial 5 - Revenue generated: 9\n",
      "Trial 6 - Revenue generated: 8\n",
      "Trial 7 - Revenue generated: 8\n",
      "Trial 8 - Revenue generated: 10\n",
      "Trial 9 - Revenue generated: 9\n",
      "Trial 10 - Revenue generated: 9\n",
      "-------------------------------------------\n",
      "Average revenue generated for all trials:  8.9\n"
     ]
    }
   ],
   "source": [
    "total_revenue = 0\n",
    "total_trials = 10\n",
    "print(\"Starting trials using Balance Algorithm...\")\n",
    "print(\"-------------------------------------------\")\n",
    "for i in range(total_trials):\n",
    "    local_companies = copy.deepcopy(global_companies)\n",
    "    revenue = balance_algorithm(local_companies, queries)\n",
    "    total_revenue = total_revenue + revenue\n",
    "    print(f\"Trial {i+1} - Revenue generated: {revenue}\")\n",
    "print(\"-------------------------------------------\")   \n",
    "print(\"Average revenue generated for all trials: \",total_revenue/total_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a2ef9e",
   "metadata": {},
   "source": [
    "### 5. Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86174f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings matrix (each row corresponds to a movie, and each column corresponds to a user)\n",
    "ratings_matrix = np.array([\n",
    "    [1, 0, 3, 0, 0, 5, 0, 0, 5, 0, 4, 0],\n",
    "    [0, 0, 5, 4, 0, 0, 4, 0, 0, 2, 1, 3],\n",
    "    [2, 4, 0, 1, 2, 0, 3, 0, 4, 3, 5, 0],\n",
    "    [0, 2, 4, 0, 5, 0, 0, 4, 0, 0, 2, 0],\n",
    "    [0, 0, 4, 3, 4, 2, 0, 0, 0, 0, 2, 5],\n",
    "    [1, 0, 3, 0, 3, 0, 0, 2, 0, 0, 4, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c92e8e0",
   "metadata": {},
   "source": [
    "#### 5.1. User-User Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c14809e-03e6-4991-aad1-4c7f9e24511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def cos_sim(user1_v, user2_v):\n",
    "    return np.dot(user1_v, user2_v) / (np.linalg.norm(user1_v) * np.linalg.norm(user2_v))\n",
    "    \n",
    "def get_top_indices(arr, x):\n",
    "    sorted_indices = np.argsort(arr)\n",
    "    # Find the highest indices, ignoring the first\n",
    "    top_indices = sorted_indices[-(x+1):-1]\n",
    "    return top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0749438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_cf(rate_m, tup_mu, neigh):\n",
    "    movie_id, user_id = tup_mu\n",
    "    \n",
    "    user_v = rate_m.T[user_id - 1]\n",
    "\n",
    "    similarities = []\n",
    "\n",
    "    for user in rate_m.T:\n",
    "        similarities.append(cos_sim(user_v, user))\n",
    "\n",
    "    N_users = get_top_indices(similarities, neigh)\n",
    "\n",
    "    pred_numer = 0\n",
    "    pred_denom = 0\n",
    "\n",
    "    for user in N_users:\n",
    "        # Weighted average\n",
    "        pred_numer += similarities[user] * rate_m[movie_id - 1][user]\n",
    "        pred_denom += similarities[user]\n",
    "\n",
    "    prediction = round(pred_numer / pred_denom, 2)    \n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c153de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuple of movie rating by users to be predicted e.g (1, 5) refers to the rating of movie 1 by user 5\n",
    "list_mu_query = [(1, 5), (3, 3)]\n",
    "\n",
    "# Neighbor selection (|N|)\n",
    "neigh = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22f8e8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "The predicted rating of movie 1 by user 5: 1.42 (User-User CF)\n",
      "-----------------------------------------------------------------\n",
      "The predicted rating of movie 3 by user 3: 1.49 (User-User CF)\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------------------------------------\")   \n",
    "for mu_query in list_mu_query:\n",
    "    predicted_rating = user_cf(ratings_matrix, mu_query, neigh)\n",
    "    print(f\"The predicted rating of movie {mu_query[0]} by user {mu_query[1]}: {predicted_rating} (User-User CF)\")\n",
    "    print(\"-----------------------------------------------------------------\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217e4ed",
   "metadata": {},
   "source": [
    "#### 5.2. Item-Item Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c03be5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_cf(rate_m, tup_mu, neigh):\n",
    "    movie_id, user_id = tup_mu\n",
    "\n",
    "    movie_v = rate_m[movie_id - 1]\n",
    "    user_v = rate_m.T[user_id - 1]\n",
    "\n",
    "    similarities = []\n",
    "\n",
    "    for movie in rate_m:\n",
    "        similarities.append(cos_sim(movie_v, movie))\n",
    "\n",
    "    N_movies = get_top_indices(similarities, neigh)\n",
    "\n",
    "    pred_numer = 0\n",
    "    pred_denom = 0\n",
    "\n",
    "    for movie in N_movies:\n",
    "        # Weighted average\n",
    "        pred_numer += similarities[movie] * user_v[movie]\n",
    "        pred_denom += similarities[movie]\n",
    "        \n",
    "    prediction = round(pred_numer / pred_denom, 2)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4b5ffe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "The predicted rating of movie 1 by user 5: 2.48 (Item-Item CF)\n",
      "-----------------------------------------------------------------\n",
      "The predicted rating of movie 3 by user 3: 3.0 (Item-Item CF)\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------------------------------------\")   \n",
    "for mu_query in list_mu_query:\n",
    "    predicted_rating = item_cf(ratings_matrix, mu_query, neigh)\n",
    "    print(f\"The predicted rating of movie {mu_query[0]} by user {mu_query[1]}: {predicted_rating} (Item-Item CF)\")\n",
    "    print(\"-----------------------------------------------------------------\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0892ce96",
   "metadata": {},
   "source": [
    "### Provide concise answers to all 5 cases in the Project 3 description below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc34aad",
   "metadata": {},
   "source": [
    "#### Case 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd09815-a6d3-49fc-b0fe-53b4da4d5ef6",
   "metadata": {},
   "source": [
    "The space complexity of DGIM is $O(\\log^2 N)$ because each bucket can represent up to $\\log N$ timestamps, resulting in a total of $log^2 N$ timestamps across all buckets. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b85a6",
   "metadata": {},
   "source": [
    "#### Case 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a32462a-8dfc-403e-9f24-aa0994765da2",
   "metadata": {},
   "source": [
    "Yes. Bloom filters can produce false positives, but not false negatives. \n",
    "\n",
    "Case presentation for the site admin: When the bloom filter algorithm returns that a username is taken, it actually means that username is most likely taken. This is because bloom filters are a probabilistic data structure. The way false positives are generated is through hash collisions. This is the case when two usernames hashes to the same value. A hash collision happens often, but for the bloom filter to return a false positive, the two usernames needs to hash to the same value for all the hash values. Therefore, to prevent two usernames to hash to the same values, we use multiple and robust hash functions. \n",
    "\n",
    "I have to disagree with you on this one, my friend. For me to be able to create a user with this username, it is simply not possible for this username to already exist. A bloom filter can not produce false negatives. The only way this would be possible, is if some of the hash functions produce different hash values from the same output. Since hash functions needs to be deterministic, this is simply not possible. And if you did not now - deterministic means that same input should always produce the same output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16cad2",
   "metadata": {},
   "source": [
    "#### Case 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadb8c18-9d07-4dbe-a185-7932ee659422",
   "metadata": {},
   "source": [
    "The main improvement area is the hashing process, and the way to increase precision is to use a better hash function or increase the number of hash functions. A better hash function means a function that generate more random and diverse hash values. By increasing the number of hash functions you can find the average of the estimates from different hash functions, thus making the final approximation more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb9e628",
   "metadata": {},
   "source": [
    "#### Case 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8a17fb-166f-48df-9a68-dc7bd743dd83",
   "metadata": {},
   "source": [
    "Greedy algorithm:\n",
    "\n",
    "Minimum revenue: 6\n",
    "\n",
    "Maximum revenue: 12\n",
    "\n",
    "Competitiveness: 6/12 = 1/2\n",
    "\n",
    "Balance algorithm:\n",
    "\n",
    "Minimum revenue: 8\n",
    "\n",
    "Maximum revenue: 10\n",
    "\n",
    "Competitveness: 8/12 = 2/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c341065",
   "metadata": {},
   "source": [
    "#### Case 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1698288f-fa70-4074-aec1-cb905424f49a",
   "metadata": {},
   "source": [
    "By analyzing the ratings matrix, it's clear that users 3 and 5 share similar tastes in the provided movies. Since user 3 rated movie 1 a 3, it is natural to assume that a prediction closer to 3 would be more accurate. Based on this intuition, item-item collaborative filtering seems like the better prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python Environment",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
